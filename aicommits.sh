#!/bin/zsh

# aicommits function - Generate commit messages using Ollama API (HTTP)
# Usage: aicommits [optional commit message prefix]
# Environment Variables:
#   OLLAMA_HOST: Default to http://localhost:11434
#   OLLAMA_MODEL: Default to the first available model

aicommits() {
    # Check if there are any staged changes
    if git diff --cached --quiet; then
        echo "No staged changes found. Please run 'git add' first."
        return 1
    fi

    # Get the diff of staged changes
    local staged_diff=$(git diff --cached)
    
    if [ -z "$staged_diff" ]; then
        echo "No staged changes to commit."
        return 1
    fi

    # Set Ollama Host
    local ollama_host="${OLLAMA_HOST:-http://localhost:11434}"
    # Remove trailing slash if present
    ollama_host="${ollama_host%/}"

    # Get model from environment variable or fetch from Ollama
    local model="${OLLAMA_MODEL:-}"
    
    if [ -z "$model" ]; then
        echo "No OLLAMA_MODEL set, fetching available models from ${ollama_host}..."
        
        # Check if Ollama is running
        if ! curl -s "${ollama_host}/api/tags" > /dev/null 2>&1; then
            echo "Error: Ollama is not running or not accessible at ${ollama_host}"
            echo "Please start Ollama or check your connection/OLLAMA_HOST variable."
            return 1
        fi
        
        # Fetch available models
        local models_json=$(curl -s "${ollama_host}/api/tags")
        
        if [ -z "$models_json" ] || [ "$models_json" = "null" ]; then
            echo "Error: Failed to fetch models from Ollama."
            return 1
        fi
        
        # Extract first model name using jq if available, otherwise use grep/sed
        if command -v jq > /dev/null 2>&1; then
            model=$(echo "$models_json" | jq -r '.models[0].name // empty' 2>/dev/null)
        else
            # Fallback: extract first model name using grep/sed
            model=$(echo "$models_json" | grep -o '"name":"[^"]*"' | head -1 | sed 's/"name":"\([^"]*\)"/\1/')
        fi
        
        if [ -z "$model" ] || [ "$model" = "null" ]; then
            echo "Error: No models found in Ollama. Please install a model first."
            return 1
        fi
        
        echo "Using model: $model"
    else
        echo "Using model from OLLAMA_MODEL: $model"
    fi

    # Prepare the prompt for Ollama
    local ollama_prompt="Generate a concise git commit message based on the following diff. 
The commit message should follow conventional commit format if applicable.
IMPORTANT: Return ONLY the commit message text, no markdown formatting, no code blocks, no backticks, no explanations.
Just the plain commit message text.

\`\`\`diff
${staged_diff}
\`\`\`"

    # Call Ollama API to generate commit message
    echo "Using server: ${ollama_host}"
    echo "Generating commit message via API..."
    
    local start_time=$SECONDS
    local commit_msg=""
    local response_json=""
    local tmp_payload=$(mktemp)

    # Clean up temp file on exit
    trap "rm -f '$tmp_payload'" EXIT

    # Use jq to build clean JSON payload in a file
    if command -v jq > /dev/null 2>&1; then
        jq -n --arg model "$model" --arg prompt "$ollama_prompt" \
           '{model: $model, prompt: $prompt, stream: false}' > "$tmp_payload"
        
        # Pipe directly to jq to avoid shell variable mangling
        # We also use tr to remove any unexpected raw control characters that might break jq
        commit_msg=$(curl -s -X POST "${ollama_host}/api/generate" \
            -H "Content-Type: application/json" \
            --data-binary @"$tmp_payload" | tr -d '\000-\010\013\014\016-\037' | jq -r '.response // empty')
    else
        # Fallback if jq is not installed
        printf '{"model": "%s", "prompt": "%s", "stream": false}' \
               "$model" "$(echo "$ollama_prompt" | sed 's/"/\\"/g' | awk '{printf "%s\\n", $0}' | sed 's/\\n$//')" > "$tmp_payload"
        
        response_json=$(curl -s -X POST "${ollama_host}/api/generate" \
            -H "Content-Type: application/json" \
            --data-binary @"$tmp_payload")
        
        commit_msg=$(echo "$response_json" | grep -o '"response":"[^"]*"' | sed 's/"response":"\(.*\)"/\1/' | sed 's/\\n/\n/g' | sed 's/\\"/"/g')
    fi

    local end_time=$SECONDS
    local duration=$(( end_time - start_time ))

    # Remove temporary file
    rm -f "$tmp_payload"
    trap - EXIT

    if [ -z "$commit_msg" ]; then
        echo "Error: Failed to generate commit message from Ollama API."
        return 1
    fi

    # Remove any triple backticks if the model included them
    commit_msg=$(echo "$commit_msg" | sed 's/```//g')
    
    # If user provided a prefix, prepend it
    if [ -n "${1:-}" ]; then
        commit_msg="${1}: ${commit_msg}"
    fi

    # Record Which AI Model is used for commit msg
    model_info="[Generated by ${model}]"
    commit_msg="${commit_msg} | ${model_info}"
    
    echo ""
    echo "Suggested commit message:"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo "$commit_msg"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo "Time taken: ${duration}s"
    echo ""

    # Ask user if they want to commit
    read "?Do you want to commit with this message? (y/N): " confirm
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        git commit -m "$(echo -e "$commit_msg")"
        echo "Committed successfully!"
    else
        echo "Commit cancelled."
    fi
}
