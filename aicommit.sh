#!/bin/zsh

# aicommit function - Generate commit messages using Ollama
# Usage: aicommit [optional commit message prefix]

aicommit() {
    # Check if there are any staged changes
    if git diff --cached --quiet; then
        echo "No staged changes found. Please run 'git add' first."
        return 1
    fi

    # Get the diff of staged changes
    local staged_diff=$(git diff --cached)
    
    if [ -z "$staged_diff" ]; then
        echo "No staged changes to commit."
        return 1
    fi

    # Get model from environment variable or fetch from Ollama
    local model="${OLLAMA_MODEL:-}"
    local lang="${AICOMMIT_LANG:-English}"
    
    if [ -z "$model" ]; then
        echo "No OLLAMA_MODEL set, fetching available models..."
        
        # Check if Ollama is running
        if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
            echo "Error: Ollama is not running or not accessible at http://localhost:11434"
            echo "Please start Ollama or check your connection."
            return 1
        fi
        
        # Fetch available models
        local models_json=$(curl -s http://localhost:11434/api/tags)
        
        if [ -z "$models_json" ] || [ "$models_json" = "null" ]; then
            echo "Error: Failed to fetch models from Ollama."
            return 1
        fi
        
        # Extract first model name using jq if available, otherwise use grep/sed
        if command -v jq > /dev/null 2>&1; then
            model=$(echo "$models_json" | jq -r '.models[0].name // empty' 2>/dev/null)
        else
            # Fallback: extract first model name using grep/sed
            model=$(echo "$models_json" | grep -o '"name":"[^"]*"' | head -1 | sed 's/"name":"\([^"]*\)"/\1/')
        fi
        
        if [ -z "$model" ] || [ "$model" = "null" ]; then
            echo "Error: No models found in Ollama. Please install a model first."
            echo "Example: ollama pull llama2"
            return 1
        fi
        
        echo "Using model: $model"
    else
        echo "Using model from OLLAMA_MODEL: $model"
    fi

    # Prepare the prompt for Ollama
    # Use ollama_prompt instead of prompt to avoid conflict with zsh's built-in prompt variable
    local ollama_prompt="Generate a concise git commit message based on the following diff. 
The commit message should follow conventional commit format if applicable.
The commit message MUST be in ${lang}.
IMPORTANT: Return ONLY the commit message text, no markdown formatting, no code blocks, no backticks, no explanations.
Just the plain commit message text.

\`\`\`diff
${staged_diff}
\`\`\`"

    local user_feedback=""
    while true; do
        # Call Ollama CLI to generate commit message (much faster than curl)
        echo "Generating commit message..."
        
        # Check if ollama command is available
        if ! command -v ollama > /dev/null 2>&1; then
            echo "Error: ollama command not found. Please install Ollama CLI."
            echo "Visit: https://ollama.ai"
            return 1
        fi
        
        local current_prompt="$ollama_prompt"
        if [ -n "$user_feedback" ]; then
            current_prompt="${current_prompt}\n\nPrevious suggested message: ${commit_msg_raw}\nUser feedback: ${user_feedback}\nPlease improve the message based on this feedback while still following the original instructions."
        fi

        # Use ollama run command - much simpler and faster
        local commit_msg=""
        local start_time=$SECONDS
        
        commit_msg=$(echo "$current_prompt" | TERM=dumb ollama run "$model" --hidethinking 2>/dev/null)
        local end_time=$SECONDS
        local duration=$(( end_time - start_time ))
        
        local ollama_exit_code=$?
        
        # Check for errors
        if [ $ollama_exit_code -ne 0 ]; then
            if [ -z "$commit_msg" ]; then
                echo "Error: Failed to generate commit message from Ollama."
                echo "Exit code: $ollama_exit_code"
                return 1
            fi
        fi
        
        if [ -z "$commit_msg" ]; then
            echo "Error: No response from Ollama."
            return 1
        fi
        
        # Clean ANSI escape codes from ollama output
        commit_msg=$(echo "$commit_msg" | sed 's/\x1b\[[0-9;]*m//g' | sed 's/\x1b\[[0-9;]*[a-zA-Z]//g' | sed 's/\x1b\[?[0-9;]*[hl]//g')
        
        if [ -z "$commit_msg" ]; then
            echo "Error: No response from Ollama."
            return 1
        fi
        
        # Remove any triple backticks
        commit_msg=$(echo "$commit_msg" | sed 's/```//g')
        
        # Store raw message for potential feedback loop
        local commit_msg_raw="$commit_msg"
        
        # If user provided a prefix, prepend it
        if [ -n "${1:-}" ]; then
            commit_msg="${1}: ${commit_msg}"
        fi
        
        # Record Which AI Model is used for commit msg
        local model_info="[Generated by ${model}]"
        local final_commit_msg="${commit_msg} | ${model_info}"
        
        echo ""
        echo "Suggested commit message:"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "$final_commit_msg"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "Time taken: ${duration}s"
        echo ""
        
        # Ask user if they want to commit
        read "?Do you want to commit? (y)es / (N)o / (r)ewrite with feedback: " confirm
        if [[ "$confirm" =~ ^[Yy]$ ]]; then
            git commit -m "$(echo -e "$final_commit_msg")"
            echo "Committed successfully!"
            break
        elif [[ "$confirm" =~ ^[Rr]$ ]]; then
            read "?Enter your feedback for the AI: " user_feedback
            echo ""
            continue
        else
            echo "Commit cancelled."
            break
        fi
    done
}

